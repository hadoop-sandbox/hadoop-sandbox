name: "hadoop-sandbox"

services:

  namenode:
    image: ${NAMENODE_IMAGE-ghcr.io/hadoop-sandbox/hadoop-hdfs-namenode:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
      - "namenode:/data"
    restart: always
    init: true
    hostname: namenode
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:9870/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  namenode-jmx-exporter:
    image: ${JMX_EXPORTER_IMAGE-ghcr.io/hadoop-sandbox/prometheus-jmx-exporter:latest}
    volumes:
      - "./conf/jmx_exporter/namenode/jmx_exporter.yaml:/etc/jmx_exporter/jmx_exporter.yaml:ro"
    restart: always
    init: true
    network_mode: service:namenode
    command: ["1128", "/etc/jmx_exporter/jmx_exporter.yaml"]
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:1128/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  datanode:
    image: ${DATANODE_IMAGE-ghcr.io/hadoop-sandbox/hadoop-hdfs-datanode:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
      - "hadoopnode:/data"
      - "dnsocket:/run/hadoop-hdfs"
    restart: always
    init: true
    ipc: shareable
    hostname: hadoopnode
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:9864/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  datanode-jmx-exporter:
    image: ${JMX_EXPORTER_IMAGE-ghcr.io/hadoop-sandbox/prometheus-jmx-exporter:latest}
    volumes:
      - "./conf/jmx_exporter/datanode/jmx_exporter.yaml:/etc/jmx_exporter/jmx_exporter.yaml:ro"
    restart: always
    init: true
    network_mode: service:datanode
    command: ["1129", "/etc/jmx_exporter/jmx_exporter.yaml"]
    depends_on:
      datanode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:1129/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  resourcemanager:
    image: ${RESOURCEMANAGER_IMAGE-ghcr.io/hadoop-sandbox/hadoop-yarn-resourcemanager:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
    restart: always
    init: true
    hostname: resourcemanager
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://resourcemanager:8088/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  resourcemanager-jmx-exporter:
    image: ${JMX_EXPORTER_IMAGE-ghcr.io/hadoop-sandbox/prometheus-jmx-exporter:latest}
    volumes:
      - "./conf/jmx_exporter/resourcemanager/jmx_exporter.yaml:/etc/jmx_exporter/jmx_exporter.yaml:ro"
    restart: always
    init: true
    network_mode: service:resourcemanager
    command: ["1126", "/etc/jmx_exporter/jmx_exporter.yaml"]
    depends_on:
      resourcemanager:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:1126/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  nodemanager:
    image: ${NODEMANAGER_IMAGE-ghcr.io/hadoop-sandbox/hadoop-yarn-nodemanager-spark:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
      - "hadoopnode:/data"
      - "dnsocket:/run/hadoop-hdfs"
    restart: always
    init: true
    network_mode: service:datanode
    ipc: service:datanode
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_ADMIN
      - SYSLOG
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:8042/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  nodemanager-jmx-exporter:
    image: ${JMX_EXPORTER_IMAGE-ghcr.io/hadoop-sandbox/prometheus-jmx-exporter:latest}
    volumes:
      - "./conf/jmx_exporter/nodemanager/jmx_exporter.yaml:/etc/jmx_exporter/jmx_exporter.yaml:ro"
    restart: always
    init: true
    network_mode: service:datanode
    command: ["1127", "/etc/jmx_exporter/jmx_exporter.yaml"]
    depends_on:
      nodemanager:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:1127/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  jobhistoryserver:
    image: ${JOBHISTORYSERVER_IMAGE-ghcr.io/hadoop-sandbox/hadoop-mapred-jobhistoryserver:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
    restart: always
    init: true
    hostname: jobhistoryserver
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
      datanode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://jobhistoryserver:19888/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  sparkhistoryserver:
    image: ${SPARKHISTORYSERVER_IMAGE-ghcr.io/hadoop-sandbox/spark-historyserver:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
      - "./conf/spark:/spark/conf:ro"
    restart: always
    init: true
    hostname: sparkhistoryserver
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
      datanode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://sparkhistoryserver:18080/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  jobhistoryserver-jmx-exporter:
    image: ${JMX_EXPORTER_IMAGE-ghcr.io/hadoop-sandbox/prometheus-jmx-exporter:latest}
    volumes:
      - "./conf/jmx_exporter/jobhistoryserver/jmx_exporter.yaml:/etc/jmx_exporter/jmx_exporter.yaml:ro"
    restart: always
    init: true
    network_mode: service:jobhistoryserver
    command: ["1130", "/etc/jmx_exporter/jmx_exporter.yaml"]
    depends_on:
      jobhistoryserver:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://localhost:1130/ || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  clientnode:
    image: ${CLIENT_IMAGE-ghcr.io/hadoop-sandbox/hadoop-client-spark:latest}
    volumes:
      - "./conf/hadoop:/hadoop/etc/hadoop:ro"
      - "./conf/spark:/spark/conf:ro"
      - "clientnodehome:/home/sandbox"
      - "clientnodessh:/etc/ssh"
    restart: always
    init: true
    hostname: clientnode
    networks:
      - default
      - front
    ports:
      - "${LISTEN_ADDRESS-127.0.0.1}:2222:22"
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
      datanode:
        condition: service_healthy
      nodemanager:
        condition: service_healthy
      jobhistoryserver:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "ssh-keyscan localhost || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

  front:
    image: ${HTTPD_IMAGE-httpd:2.4}
    environment:
      LISTEN_HOST: "${LISTEN_HOST-localhost}"
    volumes:
      - "./conf/front/conf:/usr/local/apache2/conf:ro"
      - "./conf/front/htdocs:/usr/local/apache2/htdocs:ro"
    restart: always
    init: true
    hostname: front
    networks:
      - default
      - front
    ports:
      - "${LISTEN_ADDRESS-127.0.0.1}:8042:8042"
      - "${LISTEN_ADDRESS-127.0.0.1}:8080:8080"
      - "${LISTEN_ADDRESS-127.0.0.1}:8088:8088"
      - "${LISTEN_ADDRESS-127.0.0.1}:9864:9864"
      - "${LISTEN_ADDRESS-127.0.0.1}:9870:9870"
      - "${LISTEN_ADDRESS-127.0.0.1}:19888:19888"
      - "${LISTEN_ADDRESS-127.0.0.1}:18080:18080"
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
      datanode:
        condition: service_healthy
      nodemanager:
        condition: service_healthy
      jobhistoryserver:
        condition: service_healthy
      sparkhistoryserver:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "set -Eeu -o pipefail ; exec 3<>/dev/tcp/localhost/8080 && echo -ne 'GET / HTTP/1.1\\r\\nHost: localhost\\r\\n\\r\\n' >&3 && cat <&3 | head -n 1 | grep '^HTTP/1.1 200 OK' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 1m

networks:
  default:
  front:

volumes:
  dnsocket:
  hadoopnode:
  namenode:
  clientnodehome:
  clientnodessh:
